{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4acd15",
   "metadata": {},
   "source": [
    "# Scheduling \n",
    "\n",
    "This notebook demonstrates scheduling tasks via joblib and sceduling task via DASK. The advantage of dask that it can be configured, be used for large files and it be used on a cluster. \n",
    "\n",
    "However most of the time, joblib provides a very convenient solution\n",
    "\n",
    "Both joblib and Dask were created to make heavy weight Python workloads easier to run, but they were built around slightly different design philosophies. Below is a side by side comparison of the core principles that guide each library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41692781",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body lang=en-NL style='word-wrap:break-word'>\n",
    "\n",
    "<div class=WordSection1>\n",
    "\n",
    "<p class=MsoNormal>Both&nbsp;joblib&nbsp;and&nbsp;Dask&nbsp;were created to\n",
    "make heavy‚Äëweight Python workloads easier to run, but they were built around\n",
    "slightly different design philosophies. Below is a side‚Äëby‚Äëside comparison of\n",
    "the core principles that guide each library.</p>\n",
    "\n",
    "<p class=MsoNormal>&nbsp;</p>\n",
    "\n",
    "<p class=MsoNormal>&nbsp;</p>\n",
    "\n",
    "<p class=MsoNormal>&nbsp;</p>\n",
    "\n",
    "<table class=MsoNormalTable border=0 cellpadding=0 style='background:white'>\n",
    " <thead>\n",
    "  <tr>\n",
    "   <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "   <p class=MsoNormal><span style='color:black'>Design principle</span></p>\n",
    "   </td>\n",
    "   <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "   <p class=MsoNormal><span style='color:black'>joblib</span></p>\n",
    "   </td>\n",
    "   <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "   <p class=MsoNormal><span style='color:black'>Dask</span></p>\n",
    "   </td>\n",
    "  </tr>\n",
    " </thead>\n",
    " <tr style='height:48.65pt'>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt;height:48.65pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Target workload</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt;height:48.65pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Primarily parallel&nbsp;tasks\n",
    "  and fast persistence of large NumPy‚Äëcompatible objects.</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt;height:48.65pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>General‚Äëpurpose&nbsp;parallel\n",
    "  collections&nbsp;(arrays, dataframes, bags) that mimic the APIs of NumPy,\n",
    "  pandas, and scikit‚Äëlearn, plus task graphs for more complex dependencies.</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Abstraction level</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Very thin wrapper around\n",
    "  Python‚Äôs&nbsp;multiprocessing/threading. Users write normal Python code and\n",
    "  hand it to&nbsp;Parallel/delayed.</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Higher‚Äëlevel graph abstraction (dask.delayed,&nbsp;dask.array,&nbsp;dask.dataframe).\n",
    "  The scheduler sees the whole dependency graph before execution.</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Scheduling model</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Static, simple: each delayed\n",
    "  call becomes a separate job; the scheduler just distributes them across\n",
    "  workers. No dynamic task stealing.</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Dynamic, DAG‚Äëbased: a directed\n",
    "  acyclic graph is built, then a sophisticated scheduler (single‚Äëmachine or\n",
    "  distributed) decides execution order, performs task stealing, and optimizes\n",
    "  memory usage.</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Scalability</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Works well on a&nbsp;single node&nbsp;with\n",
    "  multiple cores. Can be extended to a cluster via&nbsp;loky/dask.distributed,\n",
    "  but that‚Äôs not the primary use case.</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Designed for&nbsp;both single‚Äënode\n",
    "  and distributed clusters&nbsp;out of the box (via&nbsp;dask.distributed).\n",
    "  Scaling to hundreds of workers is a core goal.</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Caching</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Built‚Äëin&nbsp;Memory&nbsp;cache\n",
    "  that memoizes function calls on disk. Simple key‚Äëvalue lookup based on\n",
    "  argument hashing.</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Optional caching via&nbsp;persist().\n",
    "  Caching is more about persisting intermediate results of a larger graph.</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Error handling</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Errors surface as soon as a\n",
    "  worker fails; the whole&nbsp;Parallel&nbsp;call aborts.</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Errors are captured per task;\n",
    "  the scheduler can continue executing independent branches and report failures\n",
    "  in a structured way.</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Use cases emphasized</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Cross‚Äëvalidation, hyper‚Äëparameter\n",
    "  grid search, training models</span></p>\n",
    "  </td>\n",
    "  <td style='padding:.75pt .75pt .75pt .75pt'>\n",
    "  <p class=MsoNormal><span style='color:black'>Out‚Äëof‚Äëcore analytics on\n",
    "  datasets larger than RAM. Complex pipelines with inter‚Äëdependent steps. Distributed\n",
    "  training or preprocessing across a cluster</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    "</table>\n",
    "\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759e284",
   "metadata": {},
   "source": [
    "If your workload is essentially a bunch of independent\n",
    "function calls and you mainly need fast persistence, joblib‚Äôs design is a\n",
    "perfect fit. If you need to orchestrate a larger pipeline, work with data that\n",
    "exceeds memory, or run on a distributed cluster, Dask‚Äôs design principles align\n",
    "better with those goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae4f4d",
   "metadata": {},
   "source": [
    "\n",
    "Most of the times when you are using Dask, you will be using a distributed scheduler, which exists in the context of a Dask cluster. The Dask cluster is structured as follows:\n",
    "\n",
    "- a client submits the task to be executed\n",
    "- scheduler sends the task to the workers for execution\n",
    "- workers compute tasks and store / serve computed results\n",
    "\n",
    " \n",
    "https://github.com/dask/dask-tutorial/blob/main/00_overview.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=80,               # one worker per core \n",
    "    threads_per_worker=1,       # keep each worker single‚Äëthreaded ‚Üí avoids GIL contention\n",
    "    memory_limit=\"auto\",        # each worker gets roughly total_RAM / n_workers\n",
    "    processes=True,             # spawn separate Python processes (default)\n",
    "    dashboard_address=\":8781\",  # expose the dashboard on the notebook server\n",
    "    # optional: limit the amount of memory each worker can use before spilling\n",
    "    # memory_target_fraction=0.6,   # start spilling when 60‚ÄØ% of limit is used\n",
    "    # memory_spill_fraction=0.8,    # spill to disk when 80‚ÄØ% is used\n",
    ")\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733993ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dashboard link (click it to open in a new tab)\n",
    "print(\"üñ•Ô∏è  Dashboard URL:\", client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73fbac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf04ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = '/homes/fennaf/Education/BFVM24PROGRAM6/dask/data/subset_1000.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df.groupby('label')['A1BG'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "filename = '/homes/fennaf/Education/BFVM24PROGRAM6/dask/data/subset_1000.csv'\n",
    "df_dask = dd.read_csv(filename, blocksize=\"256MiB\")\n",
    "groups = df_dask.groupby('label')['A1BG'].mean()\n",
    "print(groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(groups.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1ef79",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cecd6b2",
   "metadata": {},
   "source": [
    "\n",
    "Most of the sklearn libraries have a dask equivalent. # \n",
    "\n",
    "Dask integrates with scikit through their paralel computing library joblib. It uses the dask client again to distribute the tasks to the workers. \n",
    "\n",
    "Layer                           | Controlled by   |\n",
    "| ------------------------------- | --------------- |\n",
    "| scikit-learn / joblib (default) | `n_jobs`        |\n",
    "| joblib + Dask backend           | **Dask Client** |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef59a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = np.random.random((1_000_000, 50))\n",
    "y = np.random.randint(0, 2, size=1_000_000)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, n_jobs=80)\n",
    "\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Pull results ----\n",
    "coef = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(\"Coefficients:\", coef)\n",
    "print(\"Intercept:\", intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc68338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "# X: 1_000_000 samples, 50 features, chunked for parallelism\n",
    "X = da.random.random((1_000_000, 50), chunks=(50_000, 50))\n",
    "\n",
    "# y: 1_000_000 binary labels\n",
    "y = da.random.randint(0, 2, size=(1_000_000,), chunks=(50_000,))\n",
    "X, y = X.persist(), y.persist()\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, solver=\"lbfgs\")\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8914e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = model.coef_        \n",
    "intercept = model.intercept_\n",
    "\n",
    "print(\"Coefficients:\", coef)\n",
    "print(\"Intercept:\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using parallel_backend with dask\n",
    "\n",
    "from joblib import parallel_backend\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"solver\": [\"lbfgs\"]\n",
    "}\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "\n",
    "X = np.random.random((1_000_000, 50))\n",
    "y = np.random.randint(0, 2, size=1_000_000)\n",
    "\n",
    "with parallel_backend(\"dask\", scatter=[X, y]):\n",
    "    grid.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a48b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using joblib n_jobs=-1\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"solver\": [\"lbfgs\"]\n",
    "}\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "\n",
    "\n",
    "X = np.random.random((1_000_000, 50))\n",
    "y = np.random.randint(0, 2, size=1_000_000)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask-ML model and GridSearchCV\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "# Create large Dask arrays\n",
    "X = da.random.random(\n",
    "    (1_000_000, 50),\n",
    "    chunks=(50_000, 50)\n",
    ")\n",
    "\n",
    "y = da.random.randint(\n",
    "    0, 2,\n",
    "    size=(1_000_000,),\n",
    "    chunks=(50_000,)\n",
    ")\n",
    "\n",
    "# Persist data in memory (critical for CV)\n",
    "X_p = X.persist()\n",
    "y_p = y.persist()\n",
    "\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "grid.fit(X_p, y_p)\n",
    "\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07597c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()\n",
    "client.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dask_env_20251214)",
   "language": "python",
   "name": "dask_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
